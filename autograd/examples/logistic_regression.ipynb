{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Example\n",
    "\n",
    "In this tutorial, we'll walk through how to use our automatic differentiation engine to create and train a logistic regression model to predict breast cancer. \n",
    "\n",
    "The data can be found [here](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data).\n",
    "\n",
    "Our goal here is not to create the best model to fit our data, but to simply show how to use our automatic differentiation engine to create, train, and test a logistic regression model. Thus, our model will be very simplistic for pedagogical purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We'll take look at our data and then preprocess it to be in a form appropriate to use with our automatic differentiation engine.\n",
    "\n",
    "Feel free to skip this section as it doesn't directly relate to how to use our automatic differentiation engine.\n",
    "\n",
    "Let's first import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import Variable, LogisticRegressionLayer\n",
    "import autograd\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M        17.99         10.38          122.80     1001.0   \n",
       "842517           M        20.57         17.77          132.90     1326.0   \n",
       "84300903         M        19.69         21.25          130.00     1203.0   \n",
       "84348301         M        11.42         20.38           77.58      386.1   \n",
       "84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760          0.3001   \n",
       "842517            0.08474           0.07864          0.0869   \n",
       "84300903          0.10960           0.15990          0.1974   \n",
       "84348301          0.14250           0.28390          0.2414   \n",
       "84358402          0.10030           0.13280          0.1980   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302                0.14710         0.2419  ...         25.38   \n",
       "842517                0.07017         0.1812  ...         24.99   \n",
       "84300903              0.12790         0.2069  ...         23.57   \n",
       "84348301              0.10520         0.2597  ...         14.91   \n",
       "84358402              0.10430         0.1809  ...         22.54   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "id                                                                       \n",
       "842302            17.33           184.60      2019.0            0.1622   \n",
       "842517            23.41           158.80      1956.0            0.1238   \n",
       "84300903          25.53           152.50      1709.0            0.1444   \n",
       "84348301          26.50            98.87       567.7            0.2098   \n",
       "84358402          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302               0.6656           0.7119                0.2654   \n",
       "842517               0.1866           0.2416                0.1860   \n",
       "84300903             0.4245           0.4504                0.2430   \n",
       "84348301             0.8663           0.6869                0.2575   \n",
       "84358402             0.2050           0.4000                0.1625   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302            0.4601                  0.11890  \n",
       "842517            0.2750                  0.08902  \n",
       "84300903          0.3613                  0.08758  \n",
       "84348301          0.6638                  0.17300  \n",
       "84358402          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = './data/breast_cancer.csv'\n",
    "df = pd.read_csv(csv_path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean our data.\n",
    "\n",
    "Since this tutorial is focused on using our automatic differentiaion engine rather than on machine learning itself, we'll avoid doing a deep dive into the data analysis rationalizing the methods we here to clean our data. More examples of analysis on this dataset can be found [here](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/notebooks).\n",
    "\n",
    "Let's start by dropping any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "assert df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure all of our data is numerical.\n",
    "\n",
    "We're trying to predict whether or not the partient has breast cancer, so we'll need to convert the \"diagnosis\" column to a numerical value (where 1 denotes the presence of breast cancer and 0 denotes the absence of breast cancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diagnosis = df.diagnosis.map(lambda diagnosis: float(diagnosis=='M'))\n",
    "assert {df[column].dtype for column in df.columns} == {np.dtype('float64')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                          \n",
       "842302          1.0        17.99         10.38          122.80     1001.0   \n",
       "842517          1.0        20.57         17.77          132.90     1326.0   \n",
       "84300903        1.0        19.69         21.25          130.00     1203.0   \n",
       "84348301        1.0        11.42         20.38           77.58      386.1   \n",
       "84358402        1.0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760          0.3001   \n",
       "842517            0.08474           0.07864          0.0869   \n",
       "84300903          0.10960           0.15990          0.1974   \n",
       "84348301          0.14250           0.28390          0.2414   \n",
       "84358402          0.10030           0.13280          0.1980   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302                0.14710         0.2419  ...         25.38   \n",
       "842517                0.07017         0.1812  ...         24.99   \n",
       "84300903              0.12790         0.2069  ...         23.57   \n",
       "84348301              0.10520         0.2597  ...         14.91   \n",
       "84358402              0.10430         0.1809  ...         22.54   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "id                                                                       \n",
       "842302            17.33           184.60      2019.0            0.1622   \n",
       "842517            23.41           158.80      1956.0            0.1238   \n",
       "84300903          25.53           152.50      1709.0            0.1444   \n",
       "84348301          26.50            98.87       567.7            0.2098   \n",
       "84358402          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302               0.6656           0.7119                0.2654   \n",
       "842517               0.1866           0.2416                0.1860   \n",
       "84300903             0.4245           0.4504                0.2430   \n",
       "84348301             0.8663           0.6869                0.2575   \n",
       "84358402             0.2050           0.4000                0.1625   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302            0.4601                  0.11890  \n",
       "842517            0.2750                  0.08902  \n",
       "84300903          0.3613                  0.08758  \n",
       "84348301          0.6638                  0.17300  \n",
       "84358402          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.096100</td>\n",
       "      <td>-2.071512</td>\n",
       "      <td>1.268817</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>1.567087</td>\n",
       "      <td>3.280628</td>\n",
       "      <td>2.650542</td>\n",
       "      <td>2.530249</td>\n",
       "      <td>2.215566</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885031</td>\n",
       "      <td>-1.358098</td>\n",
       "      <td>2.301575</td>\n",
       "      <td>1.999478</td>\n",
       "      <td>1.306537</td>\n",
       "      <td>2.614365</td>\n",
       "      <td>2.107672</td>\n",
       "      <td>2.294058</td>\n",
       "      <td>2.748204</td>\n",
       "      <td>1.935312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.828212</td>\n",
       "      <td>-0.353322</td>\n",
       "      <td>1.684473</td>\n",
       "      <td>1.907030</td>\n",
       "      <td>-0.826235</td>\n",
       "      <td>-0.486643</td>\n",
       "      <td>-0.023825</td>\n",
       "      <td>0.547662</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.804340</td>\n",
       "      <td>-0.368879</td>\n",
       "      <td>1.533776</td>\n",
       "      <td>1.888827</td>\n",
       "      <td>-0.375282</td>\n",
       "      <td>-0.430066</td>\n",
       "      <td>-0.146620</td>\n",
       "      <td>1.086129</td>\n",
       "      <td>-0.243675</td>\n",
       "      <td>0.280943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.578499</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>1.565126</td>\n",
       "      <td>1.557513</td>\n",
       "      <td>0.941382</td>\n",
       "      <td>1.052000</td>\n",
       "      <td>1.362280</td>\n",
       "      <td>2.035440</td>\n",
       "      <td>0.938859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.510541</td>\n",
       "      <td>-0.023953</td>\n",
       "      <td>1.346291</td>\n",
       "      <td>1.455004</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>1.081980</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>1.953282</td>\n",
       "      <td>1.151242</td>\n",
       "      <td>0.201214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.768233</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>-0.592166</td>\n",
       "      <td>-0.763792</td>\n",
       "      <td>3.280667</td>\n",
       "      <td>3.399917</td>\n",
       "      <td>1.914213</td>\n",
       "      <td>1.450431</td>\n",
       "      <td>2.864862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281217</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>-0.249720</td>\n",
       "      <td>-0.549538</td>\n",
       "      <td>3.391291</td>\n",
       "      <td>3.889975</td>\n",
       "      <td>1.987839</td>\n",
       "      <td>2.173873</td>\n",
       "      <td>6.040726</td>\n",
       "      <td>4.930672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.748758</td>\n",
       "      <td>-1.150804</td>\n",
       "      <td>1.775011</td>\n",
       "      <td>1.824624</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.538866</td>\n",
       "      <td>1.369806</td>\n",
       "      <td>1.427237</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.297434</td>\n",
       "      <td>-1.465481</td>\n",
       "      <td>1.337363</td>\n",
       "      <td>1.219651</td>\n",
       "      <td>0.220362</td>\n",
       "      <td>-0.313119</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>0.728618</td>\n",
       "      <td>-0.867590</td>\n",
       "      <td>-0.396751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                          \n",
       "842302          1.0     1.096100     -2.071512        1.268817   0.983510   \n",
       "842517          1.0     1.828212     -0.353322        1.684473   1.907030   \n",
       "84300903        1.0     1.578499      0.455786        1.565126   1.557513   \n",
       "84348301        1.0    -0.768233      0.253509       -0.592166  -0.763792   \n",
       "84358402        1.0     1.748758     -1.150804        1.775011   1.824624   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302           1.567087          3.280628        2.650542   \n",
       "842517          -0.826235         -0.486643       -0.023825   \n",
       "84300903         0.941382          1.052000        1.362280   \n",
       "84348301         3.280667          3.399917        1.914213   \n",
       "84358402         0.280125          0.538866        1.369806   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302               2.530249       2.215566  ...      1.885031   \n",
       "842517               0.547662       0.001391  ...      1.804340   \n",
       "84300903             2.035440       0.938859  ...      1.510541   \n",
       "84348301             1.450431       2.864862  ...     -0.281217   \n",
       "84358402             1.427237      -0.009552  ...      1.297434   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "id                                                                       \n",
       "842302        -1.358098         2.301575    1.999478          1.306537   \n",
       "842517        -0.368879         1.533776    1.888827         -0.375282   \n",
       "84300903      -0.023953         1.346291    1.455004          0.526944   \n",
       "84348301       0.133866        -0.249720   -0.549538          3.391291   \n",
       "84358402      -1.465481         1.337363    1.219651          0.220362   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302             2.614365         2.107672              2.294058   \n",
       "842517            -0.430066        -0.146620              1.086129   \n",
       "84300903           1.081980         0.854222              1.953282   \n",
       "84348301           3.889975         1.987839              2.173873   \n",
       "84358402          -0.313119         0.612640              0.728618   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302          2.748204                 1.935312  \n",
       "842517         -0.243675                 0.280943  \n",
       "84300903        1.151242                 0.201214  \n",
       "84348301        6.040726                 4.930672  \n",
       "84358402       -0.867590                -0.396751  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if column != 'diagnosis':\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will be very simple. We'll create a logistic regression model that takes in a value from each column and will return whether or not the patient has a 10 year risk of heart disease.\n",
    "\n",
    "Our automatic differentiation engine expects numpy arrays. \n",
    "\n",
    "Let's convert the data into two numpy arrays, one for the inputs and one for the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = df[[column for column in df.columns if column != 'diagnosis']]\n",
    "output_df = df['diagnosis']\n",
    "input_matrix = input_df.values\n",
    "output_vector = output_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split our data into a training set and test set. We'll use 50% of our data for training and 50% for testing. We'll manually set the random seeds for reproducibility purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "row_count = input_matrix.shape[0]\n",
    "row_indices = list(range(row_count))\n",
    "random.shuffle(row_indices)\n",
    "\n",
    "last_training_row_position = round(row_count*0.50)\n",
    "training_indices = row_indices[:last_training_row_position+1]\n",
    "testing_indices = row_indices[last_training_row_position+1:]\n",
    "\n",
    "training_input_matrix = input_matrix[training_indices]\n",
    "training_output_vector = output_vector[training_indices]\n",
    "testing_input_matrix = input_matrix[testing_indices]\n",
    "testing_output_vector = output_vector[testing_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression model can be implemented as a dense linear layer with a sigmoid activation. \n",
    "\n",
    "Our automatic differentiation engine provides a layer that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_layer = LogisticRegressionLayer(30, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to establish some hyperparameters for training our linear regression model. We'll be using stochastic gradient descent.\n",
    "\n",
    "In practice, we might use various batch sizes or shuffle our training data between epochs, but we'll forgo this for the sake of simplicity as the purposes of this tutorial is to show how to use our automatic differentiation engine rather than finding the best model possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 40\n",
    "learning_rate = 1e-3\n",
    "sgd = autograd.optimizer.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our training loop. We'll use cross entropy as the loss function along with L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Loss: 0.10605361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:03<00:00, 11.50it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch_iterator = tqdm(range(number_of_epochs))\n",
    "for epoch_index in epoch_iterator:\n",
    "    mean_loss = 0 \n",
    "    for x, y in zip(training_input_matrix, training_output_vector):\n",
    "        y_hat = logistic_regression_layer(x)\n",
    "        loss = y_hat.bce_loss(y)\n",
    "        mean_loss += loss.data.item()\n",
    "        sgd.take_training_step(loss)\n",
    "    mean_loss /= len(training_output_vector)\n",
    "    epoch_iterator.set_description(f'Mean Loss: {mean_loss:.8f}')\n",
    "    epoch_iterator.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how our model performs on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives:  89\n",
      "True Negatives:  188\n",
      "False Positives: 1\n",
      "False Negatives: 6\n",
      "\n",
      "Precision: 0.9888888888888889\n",
      "Recall:    0.9368421052631579\n",
      "F1:        0.9621621621621621\n",
      "Accuracy:  0.9753521126760564\n"
     ]
    }
   ],
   "source": [
    "true_positive_count = 0\n",
    "true_negative_count = 0\n",
    "false_positive_count = 0\n",
    "false_negative_count = 0\n",
    "\n",
    "for x, y in zip(testing_input_matrix, testing_output_vector):\n",
    "    y_hat = logistic_regression_layer(x)\n",
    "    y_hat = y_hat.round()\n",
    "    is_correct = y_hat == y\n",
    "    is_positive = y == 1\n",
    "    if is_correct:\n",
    "        if is_positive:\n",
    "            true_positive_count += 1\n",
    "        else:\n",
    "            true_negative_count += 1\n",
    "    else:\n",
    "        if is_positive:\n",
    "            false_positive_count += 1\n",
    "        else:\n",
    "            false_negative_count += 1\n",
    "\n",
    "precision = true_positive_count/(true_positive_count+false_positive_count)\n",
    "recall = true_positive_count/(true_positive_count+false_negative_count)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "accuracy = (true_positive_count + true_negative_count) / (true_positive_count + true_negative_count + false_positive_count + false_negative_count)\n",
    "\n",
    "print(f'True Positives:  {true_positive_count}')\n",
    "print(f'True Negatives:  {true_negative_count}')\n",
    "print(f'False Positives: {false_positive_count}')\n",
    "print(f'False Negatives: {false_negative_count}')\n",
    "print()\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall:    {recall}')\n",
    "print(f'F1:        {f1}')\n",
    "print(f'Accuracy:  {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
